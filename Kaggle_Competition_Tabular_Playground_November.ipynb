{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHlCxifi7t3-"
      },
      "source": [
        "Tabular Playground Competition "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEfaKav1AoSR",
        "outputId": "611a52aa-146a-479d-cc09-1fcb587c0a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "df = pd.concat(\n",
        "    [pd.read_csv(ZipFile('/content/drive/MyDrive/Colab Notebooks/submission_files.zip').open(i)) for i in ZipFile('/content/drive/MyDrive/Colab Notebooks/submission_files.zip').namelist()],\n",
        "    ignore_index=True, axis =1\n",
        ")\n",
        "df = df.sort_values(by=1, axis=1)\n",
        "df = df.iloc[:, :5000]\n",
        "groundTruth = pd.read_csv('/content/drive/MyDrive/RE_MACHINE_LEARNING_22/train_labels.csv', index_col='id')\n",
        "Y = groundTruth\n",
        "X = df.iloc[:20000, :]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state=42)\n",
        "TestDf = df.iloc[20000:40000, :]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "gAM4V3SEfEdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DoSKazlqSua"
      },
      "outputs": [],
      "source": [
        "def evaluateModel(Xtrain, Ytrain, Xtest, Ytest, model):\n",
        "  model.fit(Xtrain, Ytrain)\n",
        "  score = model.score(Xtrain, Ytrain) \n",
        "  print(\"Model Training score: %.2f\" %score)\n",
        "  #kfold = KFold(n_splits=5, shuffle=True)\n",
        "  #kf_cv_scores = cross_val_score(model, Xtrain, Ytrain, cv=kfold )\n",
        "  #print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())\n",
        "  ypred = model.predict(Xtest)\n",
        "  ypred =ypred.reshape(2000,1)\n",
        "  ypred = ypred.astype(np.float64)\n",
        "  mse = mean_squared_error(Ytest, ypred)\n",
        "  print(\"MSE: %.2f\" % mse)\n",
        "  smape = 1/len(Ytest) * np.sum(2*np.abs(ypred-Ytest)/(np.abs(Ytest)+np.abs(ypred))*100)\n",
        "  print(\"SMAPE: %.2f\" % smape)\n",
        "  score = log_loss(Ytest, ypred)\n",
        "  print(\"Log_Loss: %.2f\" % score)\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Model"
      ],
      "metadata": {
        "id": "6-yToLfCfIGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQl2mDTi0ZLH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "24706fed-4f17-4b33-8243-c95827e02de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Training score: 0.82\n",
            "MSE: 0.26\n",
            "SMAPE: 52.60\n",
            "Log_Loss: 9.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9682a71486f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mevaluateModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestDf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msubmisssionFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTestDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TabularPlaygroundSubmission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "xgbr = xgb.XGBRegression(verbosity=0, eta=0.001, min_child_weight=5, colsample_bylevel=0.001,n_estimators=1000, reg_lambda=50, gamma=0.005, num_boosting_rounds=1000) \n",
        "evaluateModel(X_train, Y_train, X_test, Y_test, xgbr)\n",
        "pipe = make_pipeline(xgbr)\n",
        "pipe.fit(X, Y)\n",
        "answers = pipe.predict(TestDf)\n",
        "submisssionFile = pd.DataFrame({'id': TestDf.index, 'pred': answers}).to_csv('TabularPlaygroundSubmission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCuOKuffD9UW",
        "outputId": "1a2715ac-674f-4660-95d2-4827167005ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 768 candidates, totalling 1536 fits\n",
            "[CV 1/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=3, nthreads=10, objective=reg:squarederror;, score=0.197 total time=  26.3s\n",
            "[CV 2/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=3, nthreads=10, objective=reg:squarederror;, score=0.200 total time=  29.0s\n",
            "[CV 1/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=3, nthreads=100, objective=reg:squarederror;, score=0.197 total time=  25.7s\n",
            "[CV 2/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=3, nthreads=100, objective=reg:squarederror;, score=0.200 total time=  25.6s\n",
            "[CV 1/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=3, nthreads=500, objective=reg:squarederror;, score=0.197 total time=  32.3s\n",
            "[CV 2/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=3, nthreads=500, objective=reg:squarederror;, score=0.200 total time=  26.2s\n",
            "[CV 1/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=3, nthreads=1000, objective=reg:squarederror;, score=0.197 total time=  26.2s\n",
            "[CV 2/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=3, nthreads=1000, objective=reg:squarederror;, score=0.200 total time=  26.1s\n",
            "[CV 1/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=6, nthreads=10, objective=reg:squarederror;, score=0.071 total time=  29.6s\n",
            "[CV 2/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=6, nthreads=10, objective=reg:squarederror;, score=0.061 total time=  29.6s\n",
            "[CV 1/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=6, nthreads=100, objective=reg:squarederror;, score=0.071 total time=  29.7s\n",
            "[CV 2/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=6, nthreads=100, objective=reg:squarederror;, score=0.061 total time=  29.6s\n",
            "[CV 1/2] END colsample_bytree=0.01, gamma=0.1, learning_rate=0.5, max_depth=6, nthreads=500, objective=reg:squarederror;, score=0.071 total time=  29.8s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import log_loss, make_scorer\n",
        "\n",
        "params = { 'max_depth': [3,6,10],\n",
        "            'nthreads':[10, 100, 500, 1000],\n",
        "           'learning_rate': [ 0.5, 0.01, 0.05, 0.1],\n",
        "           #'n_estimators': [100, 500, 1000],\n",
        "           'colsample_bytree': [0.01, 0.1, 0.7, 1],\n",
        "           #'min_child_weight':[5,7,10],\n",
        "           'gamma':[0.1, 0.5, 1, 10],\n",
        "           'objective':['reg:squarederror']\n",
        "\n",
        "          }\n",
        "xgbr = xgb.XGBRegressor(seed = 42)\n",
        "clf = GridSearchCV(estimator=xgbr, \n",
        "                   param_grid=params, \n",
        "                   verbose=3, cv=2)\n",
        "clf.fit(X, Y)\n",
        "print(\"Best parameters:\", clf.best_params_)\n",
        "print(\"Lowest logloss: \", (-clf.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I79WBhMaz9XU",
        "outputId": "8d1212a6-34e1-4a31-c6a9-63fcc80ff465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6000, 5000)\n",
            "(6000, 1)\n",
            "[0]\tevals-rmse:0.499857\n",
            "[1]\tevals-rmse:0.499714\n",
            "[2]\tevals-rmse:0.499573\n",
            "[3]\tevals-rmse:0.499433\n",
            "[4]\tevals-rmse:0.49929\n",
            "[5]\tevals-rmse:0.499148\n",
            "[6]\tevals-rmse:0.499007\n",
            "[7]\tevals-rmse:0.498865\n",
            "[8]\tevals-rmse:0.498725\n",
            "[9]\tevals-rmse:0.498585\n",
            "[10]\tevals-rmse:0.498443\n",
            "[11]\tevals-rmse:0.498304\n",
            "[12]\tevals-rmse:0.498163\n",
            "[13]\tevals-rmse:0.498023\n",
            "[14]\tevals-rmse:0.497881\n",
            "[15]\tevals-rmse:0.497742\n",
            "[16]\tevals-rmse:0.497602\n",
            "[17]\tevals-rmse:0.497462\n",
            "[18]\tevals-rmse:0.497324\n",
            "[19]\tevals-rmse:0.497183\n",
            "[20]\tevals-rmse:0.497045\n",
            "[21]\tevals-rmse:0.496908\n",
            "[22]\tevals-rmse:0.496771\n",
            "[23]\tevals-rmse:0.496633\n",
            "[24]\tevals-rmse:0.496494\n",
            "[25]\tevals-rmse:0.496353\n",
            "[26]\tevals-rmse:0.496214\n",
            "[27]\tevals-rmse:0.496078\n",
            "[28]\tevals-rmse:0.495937\n",
            "[29]\tevals-rmse:0.495799\n",
            "[30]\tevals-rmse:0.495661\n",
            "[31]\tevals-rmse:0.495525\n",
            "[32]\tevals-rmse:0.495386\n",
            "[33]\tevals-rmse:0.495246\n",
            "[34]\tevals-rmse:0.495113\n",
            "[35]\tevals-rmse:0.494976\n",
            "[36]\tevals-rmse:0.494836\n",
            "[37]\tevals-rmse:0.494704\n",
            "[38]\tevals-rmse:0.494568\n",
            "[39]\tevals-rmse:0.494431\n",
            "[40]\tevals-rmse:0.494297\n",
            "[41]\tevals-rmse:0.494161\n",
            "[42]\tevals-rmse:0.494029\n",
            "[43]\tevals-rmse:0.493893\n",
            "[44]\tevals-rmse:0.49376\n",
            "[45]\tevals-rmse:0.493625\n",
            "[46]\tevals-rmse:0.493489\n",
            "[47]\tevals-rmse:0.493358\n",
            "[48]\tevals-rmse:0.493224\n",
            "[49]\tevals-rmse:0.493095\n",
            "[50]\tevals-rmse:0.492961\n",
            "[51]\tevals-rmse:0.492831\n",
            "[52]\tevals-rmse:0.492703\n",
            "[53]\tevals-rmse:0.492571\n",
            "[54]\tevals-rmse:0.492438\n",
            "[55]\tevals-rmse:0.492307\n",
            "[56]\tevals-rmse:0.492176\n",
            "[57]\tevals-rmse:0.492048\n",
            "[58]\tevals-rmse:0.491917\n",
            "[59]\tevals-rmse:0.491786\n",
            "[60]\tevals-rmse:0.491653\n",
            "[61]\tevals-rmse:0.491523\n",
            "[62]\tevals-rmse:0.491393\n",
            "[63]\tevals-rmse:0.491269\n",
            "[64]\tevals-rmse:0.491138\n",
            "[65]\tevals-rmse:0.491007\n",
            "[66]\tevals-rmse:0.490882\n",
            "[67]\tevals-rmse:0.490752\n",
            "[68]\tevals-rmse:0.490625\n",
            "[69]\tevals-rmse:0.490498\n",
            "[70]\tevals-rmse:0.490369\n",
            "[71]\tevals-rmse:0.490245\n",
            "[72]\tevals-rmse:0.490117\n",
            "[73]\tevals-rmse:0.489987\n",
            "[74]\tevals-rmse:0.489865\n",
            "[75]\tevals-rmse:0.489739\n",
            "[76]\tevals-rmse:0.489615\n",
            "[77]\tevals-rmse:0.489487\n",
            "[78]\tevals-rmse:0.48936\n",
            "[79]\tevals-rmse:0.489235\n",
            "[80]\tevals-rmse:0.489113\n",
            "[81]\tevals-rmse:0.488989\n",
            "[82]\tevals-rmse:0.488864\n",
            "[83]\tevals-rmse:0.488739\n",
            "[84]\tevals-rmse:0.488619\n",
            "[85]\tevals-rmse:0.488492\n",
            "[86]\tevals-rmse:0.488371\n",
            "[87]\tevals-rmse:0.488248\n",
            "[88]\tevals-rmse:0.488129\n",
            "[89]\tevals-rmse:0.488004\n",
            "[90]\tevals-rmse:0.487878\n",
            "[91]\tevals-rmse:0.48776\n",
            "[92]\tevals-rmse:0.487639\n",
            "[93]\tevals-rmse:0.487516\n",
            "[94]\tevals-rmse:0.487395\n",
            "[95]\tevals-rmse:0.487273\n",
            "[96]\tevals-rmse:0.487154\n",
            "[97]\tevals-rmse:0.487031\n",
            "[98]\tevals-rmse:0.486911\n",
            "[99]\tevals-rmse:0.486791\n",
            "[100]\tevals-rmse:0.486671\n",
            "[101]\tevals-rmse:0.486554\n",
            "[102]\tevals-rmse:0.486431\n",
            "[103]\tevals-rmse:0.486311\n",
            "[104]\tevals-rmse:0.486194\n",
            "[105]\tevals-rmse:0.486076\n",
            "[106]\tevals-rmse:0.485955\n",
            "[107]\tevals-rmse:0.485838\n",
            "[108]\tevals-rmse:0.48572\n",
            "[109]\tevals-rmse:0.485603\n",
            "[110]\tevals-rmse:0.485482\n",
            "[111]\tevals-rmse:0.485364\n",
            "[112]\tevals-rmse:0.485247\n",
            "[113]\tevals-rmse:0.485133\n",
            "[114]\tevals-rmse:0.485013\n",
            "[115]\tevals-rmse:0.484896\n",
            "[116]\tevals-rmse:0.484777\n",
            "[117]\tevals-rmse:0.484659\n",
            "[118]\tevals-rmse:0.484545\n",
            "[119]\tevals-rmse:0.484427\n",
            "[120]\tevals-rmse:0.484314\n",
            "[121]\tevals-rmse:0.484195\n",
            "[122]\tevals-rmse:0.484081\n",
            "[123]\tevals-rmse:0.483965\n",
            "[124]\tevals-rmse:0.483849\n",
            "[125]\tevals-rmse:0.483732\n",
            "[126]\tevals-rmse:0.483617\n",
            "[127]\tevals-rmse:0.483503\n",
            "[128]\tevals-rmse:0.483387\n",
            "[129]\tevals-rmse:0.483269\n",
            "[130]\tevals-rmse:0.483156\n",
            "[131]\tevals-rmse:0.483041\n",
            "[132]\tevals-rmse:0.482928\n",
            "[133]\tevals-rmse:0.482813\n",
            "[134]\tevals-rmse:0.4827\n",
            "[135]\tevals-rmse:0.482586\n",
            "[136]\tevals-rmse:0.482473\n",
            "[137]\tevals-rmse:0.482361\n",
            "[138]\tevals-rmse:0.482246\n",
            "[139]\tevals-rmse:0.482131\n",
            "[140]\tevals-rmse:0.482021\n",
            "[141]\tevals-rmse:0.481908\n",
            "[142]\tevals-rmse:0.481795\n",
            "[143]\tevals-rmse:0.481682\n",
            "[144]\tevals-rmse:0.481574\n",
            "[145]\tevals-rmse:0.481462\n",
            "[146]\tevals-rmse:0.481347\n",
            "[147]\tevals-rmse:0.481237\n",
            "[148]\tevals-rmse:0.481128\n",
            "[149]\tevals-rmse:0.481013\n",
            "[150]\tevals-rmse:0.480905\n",
            "[151]\tevals-rmse:0.480794\n",
            "[152]\tevals-rmse:0.480683\n",
            "[153]\tevals-rmse:0.480572\n",
            "[154]\tevals-rmse:0.480462\n",
            "[155]\tevals-rmse:0.480354\n",
            "[156]\tevals-rmse:0.48024\n",
            "[157]\tevals-rmse:0.480131\n",
            "[158]\tevals-rmse:0.480023\n",
            "[159]\tevals-rmse:0.479915\n",
            "[160]\tevals-rmse:0.479806\n",
            "[161]\tevals-rmse:0.4797\n",
            "[162]\tevals-rmse:0.479588\n",
            "[163]\tevals-rmse:0.47948\n",
            "[164]\tevals-rmse:0.47937\n",
            "[165]\tevals-rmse:0.479268\n",
            "[166]\tevals-rmse:0.479156\n",
            "[167]\tevals-rmse:0.479049\n",
            "[168]\tevals-rmse:0.478939\n",
            "[169]\tevals-rmse:0.478834\n",
            "[170]\tevals-rmse:0.478726\n",
            "[171]\tevals-rmse:0.478623\n",
            "[172]\tevals-rmse:0.478514\n",
            "[173]\tevals-rmse:0.478405\n",
            "[174]\tevals-rmse:0.4783\n",
            "[175]\tevals-rmse:0.478196\n",
            "[176]\tevals-rmse:0.478092\n",
            "[177]\tevals-rmse:0.477982\n",
            "[178]\tevals-rmse:0.477882\n",
            "[179]\tevals-rmse:0.477774\n",
            "[180]\tevals-rmse:0.477665\n",
            "[181]\tevals-rmse:0.477562\n",
            "[182]\tevals-rmse:0.477457\n",
            "[183]\tevals-rmse:0.477352\n",
            "[184]\tevals-rmse:0.477245\n",
            "[185]\tevals-rmse:0.477147\n",
            "[186]\tevals-rmse:0.47704\n",
            "[187]\tevals-rmse:0.476938\n",
            "[188]\tevals-rmse:0.476834\n",
            "[189]\tevals-rmse:0.47673\n",
            "[190]\tevals-rmse:0.476625\n",
            "[191]\tevals-rmse:0.476525\n",
            "[192]\tevals-rmse:0.476422\n",
            "[193]\tevals-rmse:0.476318\n",
            "[194]\tevals-rmse:0.476216\n",
            "[195]\tevals-rmse:0.476113\n",
            "[196]\tevals-rmse:0.476008\n",
            "[197]\tevals-rmse:0.475903\n",
            "[198]\tevals-rmse:0.475805\n",
            "[199]\tevals-rmse:0.475701\n",
            "[200]\tevals-rmse:0.475602\n",
            "[201]\tevals-rmse:0.475503\n",
            "[202]\tevals-rmse:0.475401\n",
            "[203]\tevals-rmse:0.475297\n",
            "[204]\tevals-rmse:0.475195\n",
            "[205]\tevals-rmse:0.475096\n",
            "[206]\tevals-rmse:0.474995\n",
            "[207]\tevals-rmse:0.474894\n",
            "[208]\tevals-rmse:0.474797\n",
            "[209]\tevals-rmse:0.474693\n",
            "[210]\tevals-rmse:0.474595\n",
            "[211]\tevals-rmse:0.474494\n",
            "[212]\tevals-rmse:0.474397\n",
            "[213]\tevals-rmse:0.474294\n",
            "[214]\tevals-rmse:0.4742\n",
            "[215]\tevals-rmse:0.474098\n",
            "[216]\tevals-rmse:0.473997\n",
            "[217]\tevals-rmse:0.473901\n",
            "[218]\tevals-rmse:0.473801\n",
            "[219]\tevals-rmse:0.473702\n",
            "[220]\tevals-rmse:0.473602\n",
            "[221]\tevals-rmse:0.473507\n",
            "[222]\tevals-rmse:0.473408\n",
            "[223]\tevals-rmse:0.473312\n",
            "[224]\tevals-rmse:0.473214\n",
            "[225]\tevals-rmse:0.473115\n",
            "[226]\tevals-rmse:0.473021\n",
            "[227]\tevals-rmse:0.472923\n",
            "[228]\tevals-rmse:0.472828\n",
            "[229]\tevals-rmse:0.47273\n",
            "[230]\tevals-rmse:0.472635\n",
            "[231]\tevals-rmse:0.472536\n",
            "[232]\tevals-rmse:0.472444\n",
            "[233]\tevals-rmse:0.472347\n",
            "[234]\tevals-rmse:0.472255\n",
            "[235]\tevals-rmse:0.472158\n",
            "[236]\tevals-rmse:0.472063\n",
            "[237]\tevals-rmse:0.471966\n",
            "[238]\tevals-rmse:0.471876\n",
            "[239]\tevals-rmse:0.471779\n",
            "[240]\tevals-rmse:0.471686\n",
            "[241]\tevals-rmse:0.47159\n",
            "[242]\tevals-rmse:0.471496\n",
            "[243]\tevals-rmse:0.471401\n",
            "[244]\tevals-rmse:0.471311\n",
            "[245]\tevals-rmse:0.471216\n",
            "[246]\tevals-rmse:0.471125\n",
            "[247]\tevals-rmse:0.471031\n",
            "[248]\tevals-rmse:0.470937\n",
            "[249]\tevals-rmse:0.470842\n",
            "[250]\tevals-rmse:0.470754\n",
            "[251]\tevals-rmse:0.47066\n",
            "[252]\tevals-rmse:0.470568\n",
            "[253]\tevals-rmse:0.470474\n",
            "[254]\tevals-rmse:0.470386\n",
            "[255]\tevals-rmse:0.470292\n",
            "[256]\tevals-rmse:0.470204\n",
            "[257]\tevals-rmse:0.470111\n",
            "[258]\tevals-rmse:0.470017\n",
            "[259]\tevals-rmse:0.469926\n",
            "[260]\tevals-rmse:0.469834\n",
            "[261]\tevals-rmse:0.469744\n",
            "[262]\tevals-rmse:0.469652\n",
            "[263]\tevals-rmse:0.46956\n",
            "[264]\tevals-rmse:0.469474\n",
            "[265]\tevals-rmse:0.469382\n",
            "[266]\tevals-rmse:0.469294\n",
            "[267]\tevals-rmse:0.469202\n",
            "[268]\tevals-rmse:0.469112\n",
            "[269]\tevals-rmse:0.469019\n",
            "[270]\tevals-rmse:0.468934\n",
            "[271]\tevals-rmse:0.468843\n",
            "[272]\tevals-rmse:0.468751\n",
            "[273]\tevals-rmse:0.468662\n",
            "[274]\tevals-rmse:0.468574\n",
            "[275]\tevals-rmse:0.468484\n",
            "[276]\tevals-rmse:0.468397\n",
            "[277]\tevals-rmse:0.468306\n",
            "[278]\tevals-rmse:0.468219\n",
            "[279]\tevals-rmse:0.468133\n",
            "[280]\tevals-rmse:0.468043\n",
            "[281]\tevals-rmse:0.467956\n",
            "[282]\tevals-rmse:0.467866\n",
            "[283]\tevals-rmse:0.46778\n",
            "[284]\tevals-rmse:0.467691\n",
            "[285]\tevals-rmse:0.467601\n",
            "[286]\tevals-rmse:0.467518\n",
            "[287]\tevals-rmse:0.467428\n",
            "[288]\tevals-rmse:0.467346\n",
            "[289]\tevals-rmse:0.467257\n",
            "[290]\tevals-rmse:0.467172\n",
            "[291]\tevals-rmse:0.467084\n",
            "[292]\tevals-rmse:0.467\n",
            "[293]\tevals-rmse:0.466915\n",
            "[294]\tevals-rmse:0.466824\n",
            "[295]\tevals-rmse:0.466741\n",
            "[296]\tevals-rmse:0.466655\n",
            "[297]\tevals-rmse:0.466568\n",
            "[298]\tevals-rmse:0.466483\n",
            "[299]\tevals-rmse:0.4664\n",
            "[300]\tevals-rmse:0.466312\n",
            "[301]\tevals-rmse:0.466231\n",
            "[302]\tevals-rmse:0.466145\n",
            "[303]\tevals-rmse:0.466061\n",
            "[304]\tevals-rmse:0.465979\n",
            "[305]\tevals-rmse:0.465888\n",
            "[306]\tevals-rmse:0.465808\n",
            "[307]\tevals-rmse:0.465726\n",
            "[308]\tevals-rmse:0.465644\n",
            "[309]\tevals-rmse:0.465558\n",
            "[310]\tevals-rmse:0.465478\n",
            "[311]\tevals-rmse:0.465395\n",
            "[312]\tevals-rmse:0.465311\n",
            "[313]\tevals-rmse:0.465227\n",
            "[314]\tevals-rmse:0.465147\n",
            "[315]\tevals-rmse:0.465064\n",
            "[316]\tevals-rmse:0.464978\n",
            "[317]\tevals-rmse:0.4649\n",
            "[318]\tevals-rmse:0.464816\n",
            "[319]\tevals-rmse:0.464737\n",
            "[320]\tevals-rmse:0.464656\n",
            "[321]\tevals-rmse:0.464575\n",
            "[322]\tevals-rmse:0.464493\n",
            "[323]\tevals-rmse:0.464417\n",
            "[324]\tevals-rmse:0.464333\n",
            "[325]\tevals-rmse:0.46425\n",
            "[326]\tevals-rmse:0.464174\n",
            "[327]\tevals-rmse:0.464096\n",
            "[328]\tevals-rmse:0.464012\n",
            "[329]\tevals-rmse:0.463931\n",
            "[330]\tevals-rmse:0.463853\n",
            "[331]\tevals-rmse:0.463771\n",
            "[332]\tevals-rmse:0.463693\n",
            "[333]\tevals-rmse:0.463613\n",
            "[334]\tevals-rmse:0.463534\n",
            "[335]\tevals-rmse:0.463454\n",
            "[336]\tevals-rmse:0.463376\n",
            "[337]\tevals-rmse:0.463296\n",
            "[338]\tevals-rmse:0.463221\n",
            "[339]\tevals-rmse:0.46314\n",
            "[340]\tevals-rmse:0.46306\n",
            "[341]\tevals-rmse:0.462982\n",
            "[342]\tevals-rmse:0.462901\n",
            "[343]\tevals-rmse:0.462825\n",
            "[344]\tevals-rmse:0.462745\n",
            "[345]\tevals-rmse:0.462669\n",
            "[346]\tevals-rmse:0.462588\n",
            "[347]\tevals-rmse:0.462512\n",
            "[348]\tevals-rmse:0.462432\n",
            "[349]\tevals-rmse:0.462354\n",
            "[350]\tevals-rmse:0.462274\n",
            "[351]\tevals-rmse:0.462197\n",
            "[352]\tevals-rmse:0.462119\n",
            "[353]\tevals-rmse:0.462044\n",
            "[354]\tevals-rmse:0.461968\n",
            "[355]\tevals-rmse:0.461891\n",
            "[356]\tevals-rmse:0.461814\n",
            "[357]\tevals-rmse:0.461737\n",
            "[358]\tevals-rmse:0.461659\n",
            "[359]\tevals-rmse:0.461583\n",
            "[360]\tevals-rmse:0.46151\n",
            "[361]\tevals-rmse:0.461433\n",
            "[362]\tevals-rmse:0.461359\n",
            "[363]\tevals-rmse:0.461282\n",
            "[364]\tevals-rmse:0.461206\n",
            "[365]\tevals-rmse:0.461128\n",
            "[366]\tevals-rmse:0.461055\n",
            "[367]\tevals-rmse:0.46098\n",
            "[368]\tevals-rmse:0.460907\n",
            "[369]\tevals-rmse:0.460832\n",
            "[370]\tevals-rmse:0.46076\n",
            "[371]\tevals-rmse:0.460685\n",
            "[372]\tevals-rmse:0.460612\n",
            "[373]\tevals-rmse:0.460539\n",
            "[374]\tevals-rmse:0.460467\n",
            "[375]\tevals-rmse:0.460393\n",
            "[376]\tevals-rmse:0.460323\n",
            "[377]\tevals-rmse:0.460247\n",
            "[378]\tevals-rmse:0.460175\n",
            "[379]\tevals-rmse:0.460101\n",
            "[380]\tevals-rmse:0.46003\n",
            "[381]\tevals-rmse:0.459957\n",
            "[382]\tevals-rmse:0.459884\n",
            "[383]\tevals-rmse:0.459811\n",
            "[384]\tevals-rmse:0.459741\n",
            "[385]\tevals-rmse:0.459669\n",
            "[386]\tevals-rmse:0.459599\n",
            "[387]\tevals-rmse:0.459526\n",
            "[388]\tevals-rmse:0.459455\n",
            "[389]\tevals-rmse:0.459384\n",
            "[390]\tevals-rmse:0.459311\n",
            "[391]\tevals-rmse:0.45924\n",
            "[392]\tevals-rmse:0.45917\n",
            "[393]\tevals-rmse:0.4591\n",
            "[394]\tevals-rmse:0.459029\n",
            "[395]\tevals-rmse:0.45896\n",
            "[396]\tevals-rmse:0.458891\n",
            "[397]\tevals-rmse:0.458823\n",
            "[398]\tevals-rmse:0.458749\n",
            "[399]\tevals-rmse:0.45868\n",
            "[400]\tevals-rmse:0.45861\n",
            "[401]\tevals-rmse:0.458539\n",
            "[402]\tevals-rmse:0.458471\n",
            "[403]\tevals-rmse:0.458398\n",
            "[404]\tevals-rmse:0.458331\n",
            "[405]\tevals-rmse:0.458262\n",
            "[406]\tevals-rmse:0.458194\n",
            "[407]\tevals-rmse:0.458125\n",
            "[408]\tevals-rmse:0.458054\n",
            "[409]\tevals-rmse:0.457987\n",
            "[410]\tevals-rmse:0.45792\n",
            "[411]\tevals-rmse:0.45785\n",
            "[412]\tevals-rmse:0.457782\n",
            "[413]\tevals-rmse:0.457714\n",
            "[414]\tevals-rmse:0.457643\n",
            "[415]\tevals-rmse:0.457576\n",
            "[416]\tevals-rmse:0.457507\n",
            "[417]\tevals-rmse:0.457441\n",
            "[418]\tevals-rmse:0.457372\n",
            "[419]\tevals-rmse:0.457305\n",
            "[420]\tevals-rmse:0.457237\n",
            "[421]\tevals-rmse:0.457171\n",
            "[422]\tevals-rmse:0.457104\n",
            "[423]\tevals-rmse:0.457038\n",
            "[424]\tevals-rmse:0.45697\n",
            "[425]\tevals-rmse:0.456904\n",
            "[426]\tevals-rmse:0.456838\n",
            "[427]\tevals-rmse:0.456773\n",
            "[428]\tevals-rmse:0.456706\n",
            "[429]\tevals-rmse:0.456641\n",
            "[430]\tevals-rmse:0.456577\n",
            "[431]\tevals-rmse:0.456508\n",
            "[432]\tevals-rmse:0.456443\n",
            "[433]\tevals-rmse:0.456378\n",
            "[434]\tevals-rmse:0.456311\n",
            "[435]\tevals-rmse:0.456247\n",
            "[436]\tevals-rmse:0.45618\n",
            "[437]\tevals-rmse:0.456114\n",
            "[438]\tevals-rmse:0.456047\n",
            "[439]\tevals-rmse:0.455982\n",
            "[440]\tevals-rmse:0.455919\n",
            "[441]\tevals-rmse:0.455854\n",
            "[442]\tevals-rmse:0.455788\n",
            "[443]\tevals-rmse:0.455723\n",
            "[444]\tevals-rmse:0.455659\n",
            "[445]\tevals-rmse:0.455593\n",
            "[446]\tevals-rmse:0.455527\n",
            "[447]\tevals-rmse:0.455464\n",
            "[448]\tevals-rmse:0.455398\n",
            "[449]\tevals-rmse:0.455336\n",
            "[450]\tevals-rmse:0.455271\n",
            "[451]\tevals-rmse:0.455204\n",
            "[452]\tevals-rmse:0.455141\n",
            "[453]\tevals-rmse:0.455078\n",
            "[454]\tevals-rmse:0.455014\n",
            "[455]\tevals-rmse:0.454949\n",
            "[456]\tevals-rmse:0.454884\n",
            "[457]\tevals-rmse:0.454822\n",
            "[458]\tevals-rmse:0.454758\n",
            "[459]\tevals-rmse:0.454694\n",
            "[460]\tevals-rmse:0.45463\n",
            "[461]\tevals-rmse:0.454568\n",
            "[462]\tevals-rmse:0.454505\n",
            "[463]\tevals-rmse:0.454442\n",
            "[464]\tevals-rmse:0.454381\n",
            "[465]\tevals-rmse:0.454315\n",
            "[466]\tevals-rmse:0.454253\n",
            "[467]\tevals-rmse:0.454189\n",
            "[468]\tevals-rmse:0.454126\n",
            "[469]\tevals-rmse:0.454065\n",
            "[470]\tevals-rmse:0.454001\n",
            "[471]\tevals-rmse:0.453939\n",
            "[472]\tevals-rmse:0.453878\n",
            "[473]\tevals-rmse:0.453817\n",
            "[474]\tevals-rmse:0.453753\n",
            "[475]\tevals-rmse:0.453691\n",
            "[476]\tevals-rmse:0.453627\n",
            "[477]\tevals-rmse:0.453566\n",
            "[478]\tevals-rmse:0.453506\n",
            "[479]\tevals-rmse:0.453445\n",
            "[480]\tevals-rmse:0.453385\n",
            "[481]\tevals-rmse:0.453322\n",
            "[482]\tevals-rmse:0.45326\n",
            "[483]\tevals-rmse:0.453199\n",
            "[484]\tevals-rmse:0.453138\n",
            "[485]\tevals-rmse:0.453078\n",
            "[486]\tevals-rmse:0.453018\n",
            "[487]\tevals-rmse:0.452956\n",
            "[488]\tevals-rmse:0.452893\n",
            "[489]\tevals-rmse:0.45283\n",
            "[490]\tevals-rmse:0.452771\n",
            "[491]\tevals-rmse:0.45271\n",
            "[492]\tevals-rmse:0.452648\n",
            "[493]\tevals-rmse:0.452588\n",
            "[494]\tevals-rmse:0.452527\n",
            "[495]\tevals-rmse:0.452468\n",
            "[496]\tevals-rmse:0.452409\n",
            "[497]\tevals-rmse:0.452347\n",
            "[498]\tevals-rmse:0.452287\n",
            "[499]\tevals-rmse:0.452227\n",
            "[500]\tevals-rmse:0.452166\n",
            "[501]\tevals-rmse:0.452106\n",
            "[502]\tevals-rmse:0.452045\n",
            "[503]\tevals-rmse:0.451984\n",
            "[504]\tevals-rmse:0.451924\n",
            "[505]\tevals-rmse:0.451864\n",
            "[506]\tevals-rmse:0.451807\n",
            "[507]\tevals-rmse:0.451747\n",
            "[508]\tevals-rmse:0.451687\n",
            "[509]\tevals-rmse:0.451629\n",
            "[510]\tevals-rmse:0.451572\n",
            "[511]\tevals-rmse:0.451514\n",
            "[512]\tevals-rmse:0.451455\n",
            "[513]\tevals-rmse:0.451396\n",
            "[514]\tevals-rmse:0.451339\n",
            "[515]\tevals-rmse:0.451284\n",
            "[516]\tevals-rmse:0.451228\n",
            "[517]\tevals-rmse:0.45117\n",
            "[518]\tevals-rmse:0.451112\n",
            "[519]\tevals-rmse:0.451057\n",
            "[520]\tevals-rmse:0.451001\n",
            "[521]\tevals-rmse:0.450944\n",
            "[522]\tevals-rmse:0.450888\n",
            "[523]\tevals-rmse:0.450829\n",
            "[524]\tevals-rmse:0.450772\n",
            "[525]\tevals-rmse:0.450716\n",
            "[526]\tevals-rmse:0.45066\n",
            "[527]\tevals-rmse:0.450605\n",
            "[528]\tevals-rmse:0.45055\n",
            "[529]\tevals-rmse:0.450496\n",
            "[530]\tevals-rmse:0.450437\n",
            "[531]\tevals-rmse:0.450381\n",
            "[532]\tevals-rmse:0.450328\n",
            "[533]\tevals-rmse:0.450275\n",
            "[534]\tevals-rmse:0.450219\n",
            "[535]\tevals-rmse:0.450162\n",
            "[536]\tevals-rmse:0.450108\n",
            "[537]\tevals-rmse:0.450054\n",
            "[538]\tevals-rmse:0.449997\n",
            "[539]\tevals-rmse:0.449944\n",
            "[540]\tevals-rmse:0.449889\n",
            "[541]\tevals-rmse:0.449834\n",
            "[542]\tevals-rmse:0.449782\n",
            "[543]\tevals-rmse:0.449728\n",
            "[544]\tevals-rmse:0.449674\n",
            "[545]\tevals-rmse:0.449616\n",
            "[546]\tevals-rmse:0.449564\n",
            "[547]\tevals-rmse:0.449509\n",
            "[548]\tevals-rmse:0.449454\n",
            "[549]\tevals-rmse:0.449402\n",
            "[550]\tevals-rmse:0.449346\n",
            "[551]\tevals-rmse:0.449293\n",
            "[552]\tevals-rmse:0.44924\n",
            "[553]\tevals-rmse:0.449188\n",
            "[554]\tevals-rmse:0.449136\n",
            "[555]\tevals-rmse:0.449082\n",
            "[556]\tevals-rmse:0.449029\n",
            "[557]\tevals-rmse:0.448973\n",
            "[558]\tevals-rmse:0.448917\n",
            "[559]\tevals-rmse:0.448865\n",
            "[560]\tevals-rmse:0.448813\n",
            "[561]\tevals-rmse:0.448757\n",
            "[562]\tevals-rmse:0.448703\n",
            "[563]\tevals-rmse:0.448653\n",
            "[564]\tevals-rmse:0.448601\n",
            "[565]\tevals-rmse:0.44855\n",
            "[566]\tevals-rmse:0.448496\n",
            "[567]\tevals-rmse:0.448442\n",
            "[568]\tevals-rmse:0.44839\n",
            "[569]\tevals-rmse:0.448338\n",
            "[570]\tevals-rmse:0.448285\n",
            "[571]\tevals-rmse:0.448232\n",
            "[572]\tevals-rmse:0.448182\n",
            "[573]\tevals-rmse:0.448131\n",
            "[574]\tevals-rmse:0.448078\n",
            "[575]\tevals-rmse:0.448025\n",
            "[576]\tevals-rmse:0.447971\n",
            "[577]\tevals-rmse:0.447923\n",
            "[578]\tevals-rmse:0.447871\n",
            "[579]\tevals-rmse:0.44782\n",
            "[580]\tevals-rmse:0.447768\n",
            "[581]\tevals-rmse:0.447719\n",
            "[582]\tevals-rmse:0.447666\n",
            "[583]\tevals-rmse:0.447615\n",
            "[584]\tevals-rmse:0.447563\n",
            "[585]\tevals-rmse:0.447512\n",
            "[586]\tevals-rmse:0.447462\n",
            "[587]\tevals-rmse:0.447411\n",
            "[588]\tevals-rmse:0.44736\n",
            "[589]\tevals-rmse:0.447309\n",
            "[590]\tevals-rmse:0.44726\n",
            "[591]\tevals-rmse:0.447209\n",
            "[592]\tevals-rmse:0.447159\n",
            "[593]\tevals-rmse:0.447109\n",
            "[594]\tevals-rmse:0.44706\n",
            "[595]\tevals-rmse:0.447013\n",
            "[596]\tevals-rmse:0.446965\n",
            "[597]\tevals-rmse:0.446913\n",
            "[598]\tevals-rmse:0.446866\n",
            "[599]\tevals-rmse:0.446817\n",
            "[600]\tevals-rmse:0.446771\n",
            "[601]\tevals-rmse:0.44672\n",
            "[602]\tevals-rmse:0.44667\n",
            "[603]\tevals-rmse:0.446621\n",
            "[604]\tevals-rmse:0.446574\n",
            "[605]\tevals-rmse:0.446523\n",
            "[606]\tevals-rmse:0.446473\n",
            "[607]\tevals-rmse:0.446423\n",
            "[608]\tevals-rmse:0.446376\n",
            "[609]\tevals-rmse:0.446326\n",
            "[610]\tevals-rmse:0.446276\n",
            "[611]\tevals-rmse:0.446229\n",
            "[612]\tevals-rmse:0.44618\n",
            "[613]\tevals-rmse:0.446129\n",
            "[614]\tevals-rmse:0.446083\n",
            "[615]\tevals-rmse:0.446032\n",
            "[616]\tevals-rmse:0.445984\n",
            "[617]\tevals-rmse:0.445939\n",
            "[618]\tevals-rmse:0.445888\n",
            "[619]\tevals-rmse:0.445841\n",
            "[620]\tevals-rmse:0.445792\n",
            "[621]\tevals-rmse:0.445743\n",
            "[622]\tevals-rmse:0.445695\n",
            "[623]\tevals-rmse:0.445646\n",
            "[624]\tevals-rmse:0.445602\n",
            "[625]\tevals-rmse:0.445551\n",
            "[626]\tevals-rmse:0.445504\n",
            "[627]\tevals-rmse:0.445459\n",
            "[628]\tevals-rmse:0.445409\n",
            "[629]\tevals-rmse:0.445362\n",
            "[630]\tevals-rmse:0.445317\n",
            "[631]\tevals-rmse:0.445269\n",
            "[632]\tevals-rmse:0.44522\n",
            "[633]\tevals-rmse:0.445172\n",
            "[634]\tevals-rmse:0.445128\n",
            "[635]\tevals-rmse:0.445081\n",
            "[636]\tevals-rmse:0.445035\n",
            "[637]\tevals-rmse:0.444989\n",
            "[638]\tevals-rmse:0.444944\n",
            "[639]\tevals-rmse:0.444898\n",
            "[640]\tevals-rmse:0.444853\n",
            "[641]\tevals-rmse:0.444806\n",
            "[642]\tevals-rmse:0.444759\n",
            "[643]\tevals-rmse:0.444713\n",
            "[644]\tevals-rmse:0.444668\n",
            "[645]\tevals-rmse:0.444626\n",
            "[646]\tevals-rmse:0.444582\n",
            "[647]\tevals-rmse:0.444535\n",
            "[648]\tevals-rmse:0.44449\n",
            "[649]\tevals-rmse:0.444448\n",
            "[650]\tevals-rmse:0.444403\n",
            "[651]\tevals-rmse:0.444357\n",
            "[652]\tevals-rmse:0.44431\n",
            "[653]\tevals-rmse:0.444266\n",
            "[654]\tevals-rmse:0.444221\n",
            "[655]\tevals-rmse:0.444178\n",
            "[656]\tevals-rmse:0.444138\n",
            "[657]\tevals-rmse:0.444094\n",
            "[658]\tevals-rmse:0.444048\n",
            "[659]\tevals-rmse:0.444003\n",
            "[660]\tevals-rmse:0.44396\n",
            "[661]\tevals-rmse:0.443913\n",
            "[662]\tevals-rmse:0.443868\n",
            "[663]\tevals-rmse:0.443826\n",
            "[664]\tevals-rmse:0.443782\n",
            "[665]\tevals-rmse:0.443737\n",
            "[666]\tevals-rmse:0.443691\n",
            "[667]\tevals-rmse:0.443647\n",
            "[668]\tevals-rmse:0.443604\n",
            "[669]\tevals-rmse:0.443561\n",
            "[670]\tevals-rmse:0.443516\n",
            "[671]\tevals-rmse:0.443471\n",
            "[672]\tevals-rmse:0.443428\n",
            "[673]\tevals-rmse:0.443385\n",
            "[674]\tevals-rmse:0.443342\n",
            "[675]\tevals-rmse:0.4433\n",
            "[676]\tevals-rmse:0.44326\n",
            "[677]\tevals-rmse:0.443216\n",
            "[678]\tevals-rmse:0.443175\n",
            "[679]\tevals-rmse:0.443132\n",
            "[680]\tevals-rmse:0.44309\n",
            "[681]\tevals-rmse:0.443046\n",
            "[682]\tevals-rmse:0.443006\n",
            "[683]\tevals-rmse:0.442963\n",
            "[684]\tevals-rmse:0.442924\n",
            "[685]\tevals-rmse:0.442884\n",
            "[686]\tevals-rmse:0.442843\n",
            "[687]\tevals-rmse:0.4428\n",
            "[688]\tevals-rmse:0.442762\n",
            "[689]\tevals-rmse:0.442718\n",
            "[690]\tevals-rmse:0.442675\n",
            "[691]\tevals-rmse:0.442637\n",
            "[692]\tevals-rmse:0.442598\n",
            "[693]\tevals-rmse:0.442558\n",
            "[694]\tevals-rmse:0.442518\n",
            "[695]\tevals-rmse:0.442475\n",
            "[696]\tevals-rmse:0.442437\n",
            "[697]\tevals-rmse:0.442402\n",
            "[698]\tevals-rmse:0.44236\n",
            "[699]\tevals-rmse:0.442319\n",
            "[700]\tevals-rmse:0.44228\n",
            "[701]\tevals-rmse:0.442243\n",
            "[702]\tevals-rmse:0.4422\n",
            "[703]\tevals-rmse:0.442162\n",
            "[704]\tevals-rmse:0.442121\n",
            "[705]\tevals-rmse:0.442083\n",
            "[706]\tevals-rmse:0.442046\n",
            "[707]\tevals-rmse:0.44201\n",
            "[708]\tevals-rmse:0.441972\n",
            "[709]\tevals-rmse:0.441935\n",
            "[710]\tevals-rmse:0.441895\n",
            "[711]\tevals-rmse:0.441857\n",
            "[712]\tevals-rmse:0.441816\n",
            "[713]\tevals-rmse:0.441778\n",
            "[714]\tevals-rmse:0.441739\n",
            "[715]\tevals-rmse:0.441701\n",
            "[716]\tevals-rmse:0.441665\n",
            "[717]\tevals-rmse:0.441626\n",
            "[718]\tevals-rmse:0.44159\n",
            "[719]\tevals-rmse:0.441552\n",
            "[720]\tevals-rmse:0.441515\n",
            "[721]\tevals-rmse:0.441479\n",
            "[722]\tevals-rmse:0.44144\n",
            "[723]\tevals-rmse:0.441401\n",
            "[724]\tevals-rmse:0.441363\n",
            "[725]\tevals-rmse:0.441328\n",
            "[726]\tevals-rmse:0.441292\n",
            "[727]\tevals-rmse:0.441254\n",
            "[728]\tevals-rmse:0.44122\n",
            "[729]\tevals-rmse:0.441182\n",
            "[730]\tevals-rmse:0.441146\n",
            "[731]\tevals-rmse:0.441109\n",
            "[732]\tevals-rmse:0.441075\n",
            "[733]\tevals-rmse:0.441035\n",
            "[734]\tevals-rmse:0.441\n",
            "[735]\tevals-rmse:0.440962\n",
            "[736]\tevals-rmse:0.440924\n",
            "[737]\tevals-rmse:0.440889\n",
            "[738]\tevals-rmse:0.440852\n",
            "[739]\tevals-rmse:0.440814\n",
            "[740]\tevals-rmse:0.440776\n",
            "[741]\tevals-rmse:0.440738\n",
            "[742]\tevals-rmse:0.440703\n",
            "[743]\tevals-rmse:0.440666\n",
            "[744]\tevals-rmse:0.44063\n",
            "[745]\tevals-rmse:0.440592\n",
            "[746]\tevals-rmse:0.440556\n",
            "[747]\tevals-rmse:0.440519\n",
            "[748]\tevals-rmse:0.440482\n",
            "[749]\tevals-rmse:0.440445\n",
            "(6000, 1)\n"
          ]
        }
      ],
      "source": [
        "x = X.copy()\n",
        "x = pd.get_dummies(x)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, Y, test_size = .3, random_state=67)\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, Y, test_size = .2, random_state=123)\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label = y_val)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "xgb_params={\"learning_rate\": 0.001, 'lambda':0.01}\n",
        "xmodel = xgb.train(xgb_params, dtrain, num_boost_round=750, evals=[(dval, 'evals')])\n",
        "y_pred = xmodel.predict(dtest)\n",
        "print(y_test.shape)\n",
        "#print(mean_squared_error(y_test, y_pred))\n",
        "#smape = 1/len(y_test) * np.sum(2*np.abs(y_pred-y_test)/(np.abs(y_test)+np.abs(y_pred))*100)\n",
        "#print(\"SMAPE: %.2f\" % smape)\n",
        "#score = log_loss(Y_test, y_pred)\n",
        "#print(\"Log_Loss: %.2f\" % score)\n",
        "x_test = pd.get_dummies(TestDf)\n",
        "dtest = xgb.DMatrix(x_test)\n",
        "answers = xmodel.predict(dtest)\n",
        "submisssionFile = pd.DataFrame({'id': TestDf.index, 'pred': answers}).to_csv('XGBTabularPlaygroundSubmission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Regression"
      ],
      "metadata": {
        "id": "-AeVAbxsfOJf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMecpJDj0Wwo"
      },
      "outputs": [],
      "source": [
        "DecTreeReg = DecisionTreeRegressor(random_state=42)\n",
        "evaluateModel(X_train, Y_train, X_test, Y_test, DecTreeReg)\n",
        "pipe = make_pipeline(DecTreeReg)\n",
        "pipe.fit(X, Y)\n",
        "answers = pipe.predict(TestDf)\n",
        "submisssionFile = pd.DataFrame({'id': TestDf.index, 'pred': answers}).to_csv('DECTREETabularPlaygroundSubmission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regression"
      ],
      "metadata": {
        "id": "vnX1iuRzfW2N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oXWhXhzjeWz",
        "outputId": "dfd2790f-6771-489b-eaeb-b134d54b8798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Training score: 0.86\n",
            "MSE: 0.20\n",
            "SMAPE: 112.55\n",
            "Log_Loss: 0.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
          ]
        }
      ],
      "source": [
        "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "evaluateModel(X_train,  np.ravel(Y_train), X_test, Y_test, regressor)\n",
        "regressor.fit(X_train, np.ravel(Y_train))\n",
        "pipe = make_pipeline(regressor)\n",
        "pipe.fit(X, Y)\n",
        "answers = pipe.predict(TestDf)\n",
        "submisssionFile = pd.DataFrame({'id': TestDf.index, 'pred': answers}).to_csv('RandomForestTabularPlaygroundSubmission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8BSq6IivMir"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}